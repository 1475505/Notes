# 基本概念梳理

- IP：计算机网络的唯一标识。

![](http://img.070077.xyz/202204231513190.png)


# 连接属性

## `keep-alive`

- TCP保活机制。其可以一定时间间隔发送探测报文轮询客户端，若连续几个报文无响应，可判定连接结束。默认关闭。在此不多介绍。
- 也是应用层的机制。HTTP1.1默认开启，机制参考xv6的`ping-pong`。

HTTP 长连接：只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。
(短连接：请求-响应一次后就断开)



## IO 多路复用

只使用一个进程来维护多个 Socket， **进程可以通过一个系统调用函数从内核中获取多个事件**。

select 实现多路复用的方式是：将已连接的 Socket 都放到一个**文件描述符集合**，调用 select 函数将文件描述符集合**拷贝**到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过**遍历**文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合**拷贝**回用户态里，然后用户态还需要再通过**遍历**的方法找到可读或可写的 Socket，然后再对其处理。poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。**二者都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合**，

epoll 通过两个方面，很好解决了 select/poll 的问题。

1. epoll 在内核里使用**红黑树**来跟踪进程所有待检测的文件描述符，把需要监控的 socket 通过 `epoll_ctl()` 函数加入内核中的红黑树里，这样就不需要像 select/poll 每次操作时都传入整个 socket 集合，只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。

2. epoll 使用事件驱动的机制，内核里**维护了一个链表来记录就绪事件**，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 `epoll_wait()` 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。

epoll 支持两种事件触发模式，分别是**边缘触发（_edge-triggered，ET_）和 水平触发（_level-triggered，LT_）**。

- 使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，**服务器端只会从 epoll_wait 中苏醒一次**，**一般和非阻塞 I/O 搭配使用**。即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；
- 使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，**服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束**，目的是告诉我们有数据需要读取。默认。